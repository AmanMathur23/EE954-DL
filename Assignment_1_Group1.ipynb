{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935ad37f",
   "metadata": {},
   "source": [
    "#### Question 1 \n",
    "\n",
    "<p>Download the Fashion_MNIST dataset. You can find it on the official Fashion-MNIST website or by using PyTorch's torchvision.datasets module. Split the dataset into training, validation and testing sets. A common split is 80% of the data to train, 10% to validate, and 10% to test scenarios, but you can adjust this as needed. Normalize the images. This involves scaling the pixel values to a range between 0 and 1.</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400326ca",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7379fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a440d3",
   "metadata": {},
   "source": [
    "#### 2. Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcc03ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train & test df\n",
    "train = pd.read_csv('./Dataset/fashion-mnist_train.csv')\n",
    "\n",
    "test = pd.read_csv('./Dataset/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "371afd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6011d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 785)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "146621e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2537e39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73376b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 3, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data\n",
    "df_labels = df['label']\n",
    "\n",
    "df_img = df.iloc[:, 1:]\n",
    "df_img.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "462183c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_flat = df_img.values.reshape(df_img.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a725844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_images_flat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4707d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "df_images_flat = df_images_flat.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b18861e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "572d4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = pd.DataFrame.from_records(df_images_flat, columns = df_cols[1:])\n",
    "\n",
    "normalized_df['labels'] = df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1295a638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3    pixel4    pixel5  pixel6  pixel7    pixel8  \\\n",
       "0     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "1     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "2     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.019608   \n",
       "3     0.0     0.0     0.0  0.003922  0.007843     0.0     0.0  0.000000   \n",
       "4     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "\n",
       "   pixel9  pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     0.0      0.0  ...       0.0       0.0  0.000000  0.000000  0.000000   \n",
       "1     0.0      0.0  ...       0.0       0.0  0.000000  0.000000  0.000000   \n",
       "2     0.0      0.0  ...       0.0       0.0  0.117647  0.168627  0.000000   \n",
       "3     0.0      0.0  ...       0.0       0.0  0.000000  0.000000  0.003922   \n",
       "4     0.0      0.0  ...       0.0       0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  labels  \n",
       "0       0.0       0.0       0.0       0.0       2  \n",
       "1       0.0       0.0       0.0       0.0       9  \n",
       "2       0.0       0.0       0.0       0.0       6  \n",
       "3       0.0       0.0       0.0       0.0       0  \n",
       "4       0.0       0.0       0.0       0.0       3  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b7e1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset\n",
    "train_size = int(0.8 * len(normalized_df))\n",
    "val_size = int(0.1 * len(normalized_df))\n",
    "test_size = len(normalized_df) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(normalized_df,\n",
    "                                                        [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e4623",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Implement a MLP for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Implementation\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = torch.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = torch.zeros(hidden_size)\n",
    "        self.W2 = torch.randn(hidden_size, num_classes) * 0.01\n",
    "        self.b2 = torch.zeros(num_classes)\n",
    "\n",
    "    # Forward Pass (Part 2c)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)  # Flatten the image\n",
    "        \n",
    "        # First layer: input to hidden\n",
    "        self.z1 = x @ self.W1 + self.b1\n",
    "        self.a1 = self.relu(self.z1)  # Apply ReLU activation\n",
    "        \n",
    "        # Second layer: hidden to output\n",
    "        self.z2 = self.a1 @ self.W2 + self.b2\n",
    "        \n",
    "        return self.z2\n",
    "\n",
    "    def relu(self, z):\n",
    "        return torch.max(torch.zeros_like(z), z)\n",
    "    \n",
    "    def relu_derivative(self, z):\n",
    "        return (z > 0).float()\n",
    "    \n",
    "    # Backward Pass (Part 2d)\n",
    "    def backward(self, x, y, outputs, learning_rate):\n",
    "        m = y.size(0)\n",
    "        \n",
    "        dL_dz2 = outputs - y\n",
    "        \n",
    "        dL_dW2 = (self.a1.t() @ dL_dz2) / m\n",
    "        dL_db2 = dL_dz2.mean(dim=0)\n",
    "        \n",
    "        dL_da1 = dL_dz2 @ self.W2.t()\n",
    "        \n",
    "        dL_dz1 = dL_da1 * self.relu_derivative(self.z1)\n",
    "        \n",
    "        dL_dW1 = (x.view(-1, self.input_size).t() @ dL_dz1) / m\n",
    "        dL_db1 = dL_dz1.mean(dim=0)\n",
    "        \n",
    "        self.W1 -= learning_rate * dL_dW1\n",
    "        self.b1 -= learning_rate * dL_db1\n",
    "        self.W2 -= learning_rate * dL_dW2\n",
    "        self.b2 -= learning_rate * dL_db2\n",
    "\n",
    "# Cross Entropy Loss (Part 2e)\n",
    "def cross_entropy_loss(outputs, labels):\n",
    "    labels_one_hot = torch.zeros(labels.size(0), num_classes)\n",
    "    labels_one_hot[range(labels.size(0)), labels] = 1\n",
    "    loss = -torch.mean(torch.sum(labels_one_hot * torch.log_softmax(outputs, dim=1), dim=1))\n",
    "    return loss\n",
    "\n",
    "input_size = 28 * 28\n",
    "hidden_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "\n",
    "model = MLP(input_size, hidden_size, num_classes)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model.forward(images)\n",
    "        \n",
    "        loss = cross_entropy_loss(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        model.backward(images, labels, outputs, learning_rate)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Validation and Testing\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loader:\n",
    "            outputs = model.forward(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "val_accuracy = evaluate(val_loader)\n",
    "test_accuracy = evaluate(test_loader)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0aa5d",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Implement a CNN backbone model using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aee60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "\n",
    "    #define init function\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "\n",
    "        #input size. 28 channel - 1,\n",
    "        #32 - output channel from this layer,\n",
    "        #square kerner of size 3.\n",
    "        #stride defaults to 1 and padding to 0.\n",
    "        self.layer1_conv = nn.Conv2d(1, 16, 2, padding=1)\n",
    "\n",
    "        self.layer1_activ = nn.ReLU()\n",
    "        self.layer1_maxpool = nn.MaxPool2d(2, stride=1) #2x2 kernel\n",
    "\n",
    "        #layer 2, input size\n",
    "        self.layer2_conv = nn.Conv2d(16, 32, 2, padding=1)\n",
    "        self.layer2_activ = nn.ReLU()\n",
    "        self.layer2_maxpool = nn.MaxPool2d(2, stride=1)\n",
    "        #layer 3\n",
    "        self.layer3_conv = nn.Conv2d(32, 64, 2, padding=1)\n",
    "        self.layer3_activ = nn.ReLU()\n",
    "        self.layer3_maxpool = nn.MaxPool2d(2, stride=2) #14x14x64\n",
    "        #layer 4\n",
    "        self.layer4_conv = nn.Conv2d(64, 128, 2, padding=1)\n",
    "        self.layer4_activ = nn.ReLU()\n",
    "        self.layer4_maxpool = nn.MaxPool2d(2, stride=2) #7x7x128\n",
    "        #layer 5\n",
    "        self.layer5_conv = nn.Conv2d(128, 128, 2, padding=1)\n",
    "        self.layer5_activ = nn.ReLU()\n",
    "        self.layer5_maxpool = nn.MaxPool2d(2, stride=2) #4x4x256\n",
    "        #Dense layer, input size=256*\n",
    "\n",
    "        self.dense1 = nn.Linear(2048, 20)\n",
    "        #output layer\n",
    "        self.out = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #pass data x through 1st layer\n",
    "        x = self.layer1_conv(x)\n",
    "        #print(f\"shape of data after layer1_conv: {x.shape}\")\n",
    "        x = self.layer1_activ(x)\n",
    "        x = self.layer1_maxpool(x)\n",
    "        #print(f\"shape of data after layer1_maxpool: {x.shape}\")\n",
    "\n",
    "        #pass data through 2nd layer\n",
    "        x = self.layer2_conv(x)\n",
    "        #print(f\"shape of data after layer2_conv: {x.shape}\")\n",
    "        x = self.layer2_activ(x)\n",
    "        x = self.layer2_maxpool(x)\n",
    "        #print(f\"shape of data after layer2_maxpool: {x.shape}\")\n",
    "\n",
    "        #pass data through 3rd layer\n",
    "        x = self.layer3_conv(x)\n",
    "        #print(f\"shape of data after layer3_conv: {x.shape}\")\n",
    "        x = self.layer3_activ(x)\n",
    "        x = self.layer3_maxpool(x)\n",
    "        #print(f\"shape of data after layer3_maxpool: {x.shape}\")\n",
    "\n",
    "        #pass data through 4th layer\n",
    "        x = self.layer4_conv(x)\n",
    "        #print(f\"shape of data after layer4_conv: {x.shape}\")\n",
    "        x = self.layer4_activ(x)\n",
    "        x = self.layer4_maxpool(x)\n",
    "        #print(f\"shape of data after layer4_maxpool: {x.shape}\")\n",
    "\n",
    "        #pass data through 5th layer\n",
    "        x = self.layer5_conv(x)\n",
    "        #print(f\"shape of data after layer5_conv: {x.shape}\")\n",
    "        x = self.layer5_activ(x)\n",
    "        x = self.layer5_maxpool(x)\n",
    "        #print(f\"shape of data after layer5_maxpool: {x.shape}\")\n",
    "        #print(len(x[1]))\n",
    "        #print(len(x[1][1]))\n",
    "        #print(len(x[1][1][1]))\n",
    "\n",
    "        #flatten\n",
    "        x = x.view(-1, 128*4*4)\n",
    "\n",
    "        #x = self.flatten = torch.flatten(x)\n",
    "        #This method will return flattened data that will be passed to Dense layer from Q2\n",
    "        #following 2 lines will be commented after testing.\n",
    "        #print(f\"shape of data after flatten: {x.shape}\")\n",
    "        x = self.dense1(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576aa1e",
   "metadata": {},
   "source": [
    "b. Experiment with different kernel size, number of kernel each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e00600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "def cnn_model_train(train_dataloader, cnn_model, loss_func, optimizer):\n",
    "    train_data_size = len(train_dataloader.dataset)\n",
    "    #set the model to training mode\n",
    "    cnn_model.train()\n",
    "\n",
    "    for batch, (x_train, y_train) in enumerate(train_dataloader):\n",
    "      batch = batch+1\n",
    "      y_predict = cnn_model(x_train)\n",
    "      loss = loss_func(y_predict, y_train)\n",
    "\n",
    "      #backpropagate the prediction loss\n",
    "      loss.backward()\n",
    "      #adjust the parameters\n",
    "      optimizer.step()\n",
    "      #to reset the gradients of model parameters. Gradients by default add up;\n",
    "      #to prevent double-counting, we explicitly zero them at each iteration.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      #printout training metrics after batch of 100\n",
    "      if batch % 100 ==0:\n",
    "        loss = loss.item()\n",
    "        print(f\"Train loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70310135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model\n",
    "def cnn_model_test(test_dataloader, cnn_model, loss_func):\n",
    "    #set the model to evaluation (important for BN and Dropout layers)\n",
    "    cnn_model.eval()\n",
    "    num_batches = len(test_dataloader)\n",
    "\n",
    "    #initialize\n",
    "    test_loss, correct = 0, 0\n",
    "    #ensure that no grad are computed during test mode\n",
    "    with torch.no_grad():\n",
    "        for batch, (x_valid, y_valid) in enumerate(test_dataloader):\n",
    "            batch = batch+1\n",
    "            predict = cnn_model(x_valid)\n",
    "            test_loss = loss_func(predict, y_valid)\n",
    "            if batch % 100 ==0:\n",
    "                test_loss = test_loss/num_batches\n",
    "                print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN_Model()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "train_dataloader, test_dataloader = FMNIST_DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a0e5a",
   "metadata": {},
   "source": [
    "c. Try different weight initialization methods (random, Xavier, He)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for block is for unit testing only NOT BE EXECUTED IN ACTUAL RUN\n",
    "for i, (x,y) in enumerate(train_dataloader):\n",
    "    print(i)\n",
    "    #print(x[0])\n",
    "    #print(y[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d166987",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for i in range(epochs):\n",
    "    print(f\"epoch {i+1}\")\n",
    "    cnn_model_train(train_dataloader, cnn_model, loss_func, optimizer)\n",
    "    cnn_model_test(test_dataloader, cnn_model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017bcb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924391e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b812eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abhay_venv",
   "language": "python",
   "name": "abhay_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
